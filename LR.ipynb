{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOixCJj1Iev1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import os\n",
        "import imutils\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import imageio\n",
        "from PIL import Image\n",
        "from imutils import face_utils\n",
        "import time\n",
        "from keras.utils import np_utils, generic_utils\n",
        "import shutil\n",
        "from skimage.transform import resize\n",
        "from sklearn.utils import shuffle\n",
        "from skimage.io import imread, imsave, imshow\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Input,Activation, Bidirectional,ConvLSTM3D,ConvLSTM2D,ZeroPadding3D, TimeDistributed, LSTM, GRU, Reshape,BatchNormalization, ConvLSTM2D,GlobalMaxPooling2D\n",
        "from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "from keras.applications.vgg16 import VGG16\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm5NGf9Cc4cU",
        "outputId": "d0c0a928-51e3-4faf-f877-e6ae6f2504cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSKvVKwXdXy1",
        "outputId": "42939352-0bfd-4ac8-de64-60277679c38e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken to unzip: 107.31625032424927 secs\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "!unzip '/content/gdrive/MyDrive/Colab Notebooks/miracl.zip' > /dev/null\n",
        "t2 = time.time()\n",
        "print(f\"Time taken to unzip: {t2-t1} secs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otPwnx81ImAq"
      },
      "outputs": [],
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_val = []\n",
        "y_val = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "words = ['Begin','Choose','Connection','Navigation','Next', 'Previous', 'Start','Stop','Hello','Web']\n",
        "phrases = [\"Stop navigaton\",\"Excuse me\",\"I am sorry\",\"Thank you\",'Good bye','I love this game','Nice to meet you','You are welcome','How are you?','Have a good time']\n",
        "phrases_di = {i:phrases[i] for i in range(len(phrases))}\n",
        "\n",
        "\n",
        "words_di = {i:words[i] for i in range(len(words))}\n",
        "\n",
        "unseen_test = ['F04']\n",
        "unseen_validation = ['F07','M02']\n",
        "\n",
        "\n",
        "starting_path = '/content/dataset/dataset'\n",
        "\n",
        "\n",
        "people = ['F01','F02','F04','F05','F06','F07','F08','F09','F10','F11','M01','M02','M04','M07','M08']\n",
        "data_types = ['phrases']\n",
        "folder_nums = ['01','02','03','04','05','06','07','08','09','10']\n",
        "instances = ['01','02','03','04','05','06','07','08','09','10']\n",
        "image_nums = ['color_001','color_002','color_003','color_004','color_005','color_006','color_007','color008','color_009','color_010','color_11','color_12','color_13']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gdNe3kXPZB2"
      },
      "outputs": [],
      "source": [
        "people = ['F01']\n",
        "unseen_test = ['07','09','10']\n",
        "train = ['10']\n",
        "unseen_validation = ['08']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsfix1SBAVUx"
      },
      "outputs": [],
      "source": [
        "def crop_and_save():\n",
        "    MAX_HEIGHT = 100\n",
        "    MAX_WIDTH = 100\n",
        "    max_seq_length = 10\n",
        "    t1 = time.time()\n",
        "    hog_face_detector = dlib.get_frontal_face_detector()\n",
        "    dlib_facelandmark = dlib.shape_predictor('/content/shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "    for person in people:\n",
        "        tx1 = time.time()\n",
        "        for data_type in data_types:\n",
        "            for word_index,folder in enumerate(tqdm(folder_nums)):\n",
        "                for instance in instances:\n",
        "                    sequence = []\n",
        "                    for image in image_nums:\n",
        "                        path = starting_path + '/' + person + '/' + data_type + '/' + folder + '/'+instance + '/' + image + '.jpg'\n",
        "                        #print(path)\n",
        "\n",
        "                        if(os.path.exists(path) and path.__contains__('color')):\n",
        "                            #print(path)\n",
        "                            frame = cv2.imread(path)\n",
        "                            \n",
        "                            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                            #gray = frame\n",
        "                            x_arr = []\n",
        "                            y_arr = []\n",
        "                            gray = imutils.resize(gray, width=500)\n",
        "                            copy = gray.copy()\n",
        "                            faces = hog_face_detector(gray)\n",
        "                            for face in faces:\n",
        "\n",
        "                                face_landmarks = dlib_facelandmark(gray, face)\n",
        "\n",
        "                                for n in range(48, 68):\n",
        "                                    x = face_landmarks.part(n).x\n",
        "                                    y = face_landmarks.part(n).y\n",
        "                                    x_arr.append(x)\n",
        "                                    y_arr.append(y)\n",
        "                                    #print(face_landmarks.part(n))\n",
        "\n",
        "                                    xmax = max(x_arr)\n",
        "                                    xmin = min(x_arr)\n",
        "                                    ymax = max(y_arr)\n",
        "                                    ymin = min(y_arr)\n",
        "\n",
        "                                    cv2.circle(gray, (x, y), 1, (0, 255, 255), 1)\n",
        "\n",
        "                            copy = copy[ymin-1:ymax+3, xmin-5:xmax+5]\n",
        "                            #print(\"Gray mouth shape: \", copy.shape)\n",
        "\n",
        "                            scale_percent = 200\n",
        "                            \n",
        "                            width2 = 100\n",
        "\n",
        "                            height2 = 100\n",
        "                            dim = (width2, height2)\n",
        "                            resized_cropped = cv2.resize(copy, dim, interpolation = cv2.INTER_AREA)\n",
        "                            \n",
        "                            #print(resized_cropped.shape)\n",
        "                            MAX_WIDTH, MAX_HEIGHT = resized_cropped.shape\n",
        "                            max_seq_length = 10\n",
        "                            #resized_cropped = resized_cropped*255\n",
        "                            resized_cropped = resized_cropped.astype(np.uint8)\n",
        "                            #print(\"Shape: \",resized_cropped.shape)\n",
        "                            sequence.append(resized_cropped)\n",
        "                        else:\n",
        "                            continue\n",
        "                    pad_array = [np.zeros((MAX_WIDTH, MAX_HEIGHT))]           \n",
        "                    sequence.extend(pad_array * (max_seq_length - len(sequence)))\n",
        "                    \n",
        "                    sequence = np.array(sequence)\n",
        "                    if people in unseen_test:\n",
        "                        #x_train.append(sequence) #comment out\n",
        "                        #y_train.append(word_index) #comment out\n",
        "                        x_test.append(sequence)\n",
        "                        y_test.append(word_index)\n",
        "                    elif people in unseen_validation:\n",
        "                        x_val.append(sequence)\n",
        "                        y_val.append(word_index)\n",
        "                    else:\n",
        "                        x_train.append(sequence)\n",
        "                        y_train.append(word_index)\n",
        "        tx2 = time.time()\n",
        "        print(f'Finished reading images for person {person}. Time taken : {tx2 - tx1} secs.')\n",
        "    t2 = time.time()\n",
        "    print(f\"Time taken to create 3D Tensor from cropped lip images: {t2 - t1} secs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfY1zpQrAYnh",
        "outputId": "c890b97c-1f1a-47bd-8c14-6b0bf5dae81c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:29<00:00,  2.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person F01. Time taken : 29.699921369552612 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:30<00:00,  3.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person F02. Time taken : 30.650188446044922 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:30<00:00,  3.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person F04. Time taken : 30.606186389923096 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:30<00:00,  3.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person F05. Time taken : 30.57828116416931 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:32<00:00,  3.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person F06. Time taken : 32.06891322135925 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:30<00:00,  3.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person F07. Time taken : 30.650315523147583 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:30<00:00,  3.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person F08. Time taken : 30.656086444854736 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:29<00:00,  2.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person F09. Time taken : 29.8863365650177 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:28<00:00,  2.87s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person F10. Time taken : 28.734182596206665 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:30<00:00,  3.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person F11. Time taken : 30.408929347991943 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:30<00:00,  3.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person M01. Time taken : 30.616491556167603 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:31<00:00,  3.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person M02. Time taken : 31.79002332687378 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:31<00:00,  3.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person M04. Time taken : 31.417670488357544 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:31<00:00,  3.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person M07. Time taken : 31.372987270355225 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:29<00:00,  2.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading images for person M08. Time taken : 29.846840620040894 secs.\n",
            "Time taken to create 3D Tensor from cropped lip images: 459.9555892944336 secs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "crop_and_save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "rPwJhx8L3QPI",
        "outputId": "65c0e316-90b7-4c67-9a4f-472dacd41661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 100)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1500, 10, 100, 100)\n"
          ]
        }
      ],
      "source": [
        "x_train = np.array(x_train)\n",
        "one =x_train[0][0]\n",
        "print(one.shape)\n",
        "plt.imshow(one,cmap='gray')\n",
        "plt.show()\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQgmcMJTAba5",
        "outputId": "d5fbc755-9667-4846-c626-09d16d9cfa95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X Training shape:  (1500, 10, 100, 100)\n",
            "X Test shape:  (0,)\n",
            "X Validation shape:  (0,)\n",
            "Y Training shape:  (1500,)\n",
            "Y Test shape:  (0,)\n",
            "Y Validation shape:  (0,)\n"
          ]
        }
      ],
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "x_val = np.array(x_val)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "print(\"X Training shape: \",x_train.shape)\n",
        "print(\"X Test shape: \",x_test.shape)\n",
        "print(\"X Validation shape: \",x_val.shape)\n",
        "print(\"Y Training shape: \",y_train.shape)\n",
        "print(\"Y Test shape: \",y_test.shape)\n",
        "print(\"Y Validation shape: \",y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuPGgXSg3Om6",
        "outputId": "8152777f-a1e9-4b78-fd9e-80159fcb24db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "x =np.isnan(x_train).sum()\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GnRD6tcAdL0"
      },
      "outputs": [],
      "source": [
        "def normalize_it(X):\n",
        "    v_min = X.min(axis=(2, 3), keepdims=True)\n",
        "    v_max = X.max(axis=(2, 3), keepdims=True)\n",
        "    #print(v_min)\n",
        "    #print('Max: ',v_max)\n",
        "    X = (X - v_min)/(v_max - v_min)\n",
        "    X = np.nan_to_num(X)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV9YKXOcAeoK"
      },
      "outputs": [],
      "source": [
        "def clean(x_train,x_val,x_test,y_train,y_val,y_test):\n",
        "    print()\n",
        "    print(\"Normalizing data...\")\n",
        "    t1 = time.time()\n",
        "    x_train = normalize_it(x_train)\n",
        "    #print(X_train)\n",
        "    x_val = normalize_it(x_val)\n",
        "    x_test = normalize_it(x_test)\n",
        "    t2 =time.time()\n",
        "    print()\n",
        "    print(f\"Time taken to normalize images: {t2 - t1} secs\")\n",
        "\n",
        "    print()\n",
        "    print(\"One hot encoding labels...\")\n",
        "    t3 = time.time()\n",
        "    y_train = np_utils.to_categorical(y_train, 10)\n",
        "    y_test = np_utils.to_categorical(y_test, 10)\n",
        "    y_val = np_utils.to_categorical(y_val, 10)\n",
        "    t4 = time.time()\n",
        "    print()\n",
        "    print(f\"Time taken to convert labels to categorical: {t4 - t3} secs\")\n",
        "\n",
        "    print()\n",
        "    print(\"Shuffling data...\")\n",
        "    t5 = time.time()\n",
        "    X_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
        "    X_test, y_test = shuffle(x_test, y_test, random_state=0)\n",
        "    X_val, y_val = shuffle(x_val, y_val, random_state=0)\n",
        "    t6 = time.time()\n",
        "    print()\n",
        "    print(f\"Time taken to shuffle data: {t6 - t5} secs\")\n",
        "    \n",
        "    print()\n",
        "    print(\"Reshaping data...\")\n",
        "    t7 = time.time()\n",
        "    x_train = np.expand_dims(x_train, axis=4)\n",
        "    x_val = np.expand_dims(x_val, axis=4)\n",
        "    x_test = np.expand_dims(x_test, axis=4)\n",
        "    t8 = time.time()\n",
        "    print()\n",
        "    print(f\"Time taken to reshape data: {t8 - t7} secs\")\n",
        "    print()\n",
        "\n",
        "    print(x_train.shape)\n",
        "    print(x_val.shape)\n",
        "    print(x_test.shape)\n",
        "    return x_train, x_val, x_test, y_train, y_val, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8I6WOeYAg5I",
        "outputId": "81550783-fa71-4b03-be6c-b228d804886a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Normalizing data...\n",
            "\n",
            "Time taken to normalize images: 0.311004638671875 secs\n",
            "\n",
            "One hot encoding labels...\n",
            "\n",
            "Time taken to convert labels to categorical: 0.0001392364501953125 secs\n",
            "\n",
            "Shuffling data...\n",
            "\n",
            "Time taken to shuffle data: 0.06472086906433105 secs\n",
            "\n",
            "Reshaping data...\n",
            "\n",
            "Time taken to reshape data: 5.316734313964844e-05 secs\n",
            "\n",
            "(90, 10, 100, 100, 1)\n",
            "(10, 10, 100, 100, 1)\n",
            "(30, 10, 100, 100, 1)\n"
          ]
        }
      ],
      "source": [
        "x_train, x_val, x_test, y_train, y_val, y_test = clean(x_train,x_val,x_test,y_train,y_val,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxaxgDGKGCkM"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "\n",
        "MODEL WITH 100% TRAINING ACCURACY\n",
        "\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(32, (3, 3, 3), strides = 1, input_shape=(10, 100, 100, 1), activation='relu', padding='valid'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "model.add(Conv3D(64, (3, 3, 3), activation='relu', strides=1))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
        "\n",
        "\n",
        "shape = (1,10,10,128)\n",
        "model.add((Flatten()))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy',optimizer = 'Adam',metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFrV8vKuQ1Df"
      },
      "outputs": [],
      "source": [
        "plot_model(model,to_file='model.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XpZmEwxQ2ma"
      },
      "outputs": [],
      "source": [
        "def myprint(s):\n",
        "    with open('modelsummary.txt','a') as f:\n",
        "        print(s, file=f)\n",
        "\n",
        "model.summary(print_fn=myprint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4YzSYVXAmGX"
      },
      "outputs": [],
      "source": [
        "  \n",
        "t1 = time.time()\n",
        "#history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks = [earlyStopping], epochs=45)\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=35)\n",
        "t2 = time.time()\n",
        "print()\n",
        "print(f\"Training time : {(t2 - t1)/60} mins.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxPQkA7IAmva"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX2b46Q0Aoka"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xlim(1, 40)\n",
        "# plt.ylim(0, 3)\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WReulqF6AqKw",
        "outputId": "1157f214-9521-4cb8-84d6-8572f37a7163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 272ms/step\n"
          ]
        }
      ],
      "source": [
        "#pred = model.predict(x_test)\n",
        "ypred = model.predict(x_test)\n",
        "# predicted_words = [words[i] for i in np.argmax(ypred, axis=1)]\n",
        "# actual_words = [words[i] for i in np.argmax(y_test,axis=1)]\n",
        "predicted_words = [words[i] for i in np.argmax(ypred, axis=1)]\n",
        "actual_words = [words[i] for i in np.argmax(y_test,axis=1)]\n",
        "#actual_words = [words[i] for i in np.argmax(y_train,axis=1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVHWWqPV6kA6"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "for p, a in zip(predicted_words, actual_words):\n",
        "    if p == a:\n",
        "        correct += 1\n",
        "    print(f\"Predicted : {p} \\t Actual : {a}\")\n",
        "\n",
        "accuracy = correct/len(actual_words)\n",
        "print()\n",
        "print()\n",
        "print(f\"Accuracy = {accuracy*100}% on testing data\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
