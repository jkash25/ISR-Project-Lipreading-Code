{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import drive\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import imutils\n",
    "import dlib\n",
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from imutils import face_utils\n",
    "import time\n",
    "from keras.utils import np_utils, generic_utils\n",
    "import shutil\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.io import imread, imsave, imshow\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Input,Activation, Bidirectional,ConvLSTM3D,ConvLSTM2D,ZeroPadding3D, TimeDistributed, LSTM, GRU, Reshape,BatchNormalization, ConvLSTM2D,GlobalMaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from keras.applications.vgg16 import VGG16\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "words = ['Begin','Choose','Connection','Navigation','Next', 'Previous', 'Start','Stop','Hello','Web']\n",
    "phrases = [\"Stop navigaton\",\"Excuse me\",\"I am sorry\",\"Thank you\",'Good bye','I love this game','Nice to meet you','You are welcome','How are you?','Have a good time']\n",
    "phrases_di = {i:phrases[i] for i in range(len(phrases))}\n",
    "\n",
    "\n",
    "words_di = {i:words[i] for i in range(len(words))}\n",
    "\n",
    "unseen_test = ['Jai04']\n",
    "unseen_validation = ['Jai02','Jai07']\n",
    "\n",
    "\n",
    "starting_path = 'C:\\\\Users\\\\Jai K\\\\CS Stuff\\\\Python\\\\ISR Project\\\\self_training\\\\'\n",
    "\n",
    "\n",
    "people = ['Jai01','Jai02','Jai03','Jai04','Jai05','Jai06','Jai07','Jai08','Jai09','Jai10']\n",
    "data_types = ['words']\n",
    "folder_nums = ['01','02','03','04','05','06','07','08','09','10']\n",
    "instances = ['01','02','03','04','05','06','07','08','09','10']\n",
    "image_nums = ['frame001','frame002','frame003','frame004','frame005','frame006','frame007','frame008','frame009','frame010']\n",
    "max_seq_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_save():\n",
    "    t1 = time.time()\n",
    "    for person in people:\n",
    "        tx1 = time.time()\n",
    "        for data_type in data_types:\n",
    "            for word_index,folder_num in enumerate(tqdm(folder_nums)):\n",
    "                for instance in instances:\n",
    "                    sequence = []\n",
    "                    for image in image_nums:\n",
    "                        path = starting_path+person+\"\\\\\"+data_type+\"\\\\\"+folder_num+\"\\\\\"+instance+\"\\\\\"+image\n",
    "                        frame = cv2.imread(path)\n",
    "                        frame = frame.astype(np.uint8)\n",
    "                        sequence.append(frame)\n",
    "                    pad_array = [np.zeros((100,100))]\n",
    "                    sequence.extend(pad_array*(max_seq_length-len(sequence)))\n",
    "                    sequence = np.array(sequence)\n",
    "                    if people in unseen_test:\n",
    "                        x_test.append(sequence)\n",
    "                        y_test.append(word_index)\n",
    "                    elif people in unseen_validation:\n",
    "                        x_val.append(sequence)\n",
    "                        y_val.append(word_index)\n",
    "                    else:\n",
    "                        x_train.append(sequence)\n",
    "                        y_train.append(word_index)\n",
    "        tx2 = time.time()\n",
    "        print(f\"Finished reading images for {person}. Time taken: {tx2-tx1} seconds.\")\n",
    "    t2 = time.time()\n",
    "    print(f\"Time taken to create 3D Tensor from cropped lip images: {t2-t1} seconds.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "x_val = np.array(x_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(\"X Training shape: \",x_train.shape)\n",
    "print(\"X Test shape: \",x_test.shape)\n",
    "print(\"X Validation shape: \",x_val.shape)\n",
    "print(\"Y Training shape: \",y_train.shape)\n",
    "print(\"Y Test shape: \",y_test.shape)\n",
    "print(\"Y Validation shape: \",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =np.isnan(x_train).sum()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_it(X):\n",
    "    v_min = X.min(axis=(2, 3), keepdims=True)\n",
    "    v_max = X.max(axis=(2, 3), keepdims=True)\n",
    "    #print(v_min)\n",
    "    #print('Max: ',v_max)\n",
    "    X = (X - v_min)/(v_max - v_min)\n",
    "    X = np.nan_to_num(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x_train,x_val,x_test,y_train,y_val,y_test):\n",
    "    print()\n",
    "    print(\"Normalizing data...\")\n",
    "    t1 = time.time()\n",
    "    x_train = normalize_it(x_train)\n",
    "    #print(X_train)\n",
    "    x_val = normalize_it(x_val)\n",
    "    x_test = normalize_it(x_test)\n",
    "    t2 =time.time()\n",
    "    print()\n",
    "    print(f\"Time taken to normalize images: {t2 - t1} secs\")\n",
    "\n",
    "    print()\n",
    "    print(\"One hot encoding labels...\")\n",
    "    t3 = time.time()\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    y_val = np_utils.to_categorical(y_val, 10)\n",
    "    t4 = time.time()\n",
    "    print()\n",
    "    print(f\"Time taken to convert labels to categorical: {t4 - t3} secs\")\n",
    "\n",
    "    print()\n",
    "    print(\"Shuffling data...\")\n",
    "    t5 = time.time()\n",
    "    X_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
    "    X_test, y_test = shuffle(x_test, y_test, random_state=0)\n",
    "    X_val, y_val = shuffle(x_val, y_val, random_state=0)\n",
    "    t6 = time.time()\n",
    "    print()\n",
    "    print(f\"Time taken to shuffle data: {t6 - t5} secs\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Reshaping data...\")\n",
    "    t7 = time.time()\n",
    "    x_train = np.expand_dims(x_train, axis=4)\n",
    "    x_val = np.expand_dims(x_val, axis=4)\n",
    "    x_test = np.expand_dims(x_test, axis=4)\n",
    "    t8 = time.time()\n",
    "    print()\n",
    "    print(f\"Time taken to reshape data: {t8 - t7} secs\")\n",
    "    print()\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(x_val.shape)\n",
    "    print(x_test.shape)\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = clean(x_train,x_val,x_test,y_train,y_val,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "MODEL WITH 100% TRAINING ACCURACY\n",
    "\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(32, (3, 3, 3), strides = 1, input_shape=(10, 100, 100, 1), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "model.add(Conv3D(64, (3, 3, 3), activation='relu', strides=1))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "\n",
    "shape = (1,10,10,128)\n",
    "model.add((Flatten()))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "#history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks = [earlyStopping], epochs=45)\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=35)\n",
    "t2 = time.time()\n",
    "print()\n",
    "print(f\"Training time : {(t2 - t1)/60} mins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(1, 40)\n",
    "# plt.ylim(0, 3)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(x_test)\n",
    "predicted_words = [words[i] for i in np.argmax(ypred, axis=1)]\n",
    "actual_words = [words[i] for i in np.argmax(y_test,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for p, a in zip(predicted_words, actual_words):\n",
    "    if p == a:\n",
    "        correct += 1\n",
    "    print(f\"Predicted : {p} \\t Actual : {a}\")\n",
    "\n",
    "accuracy = correct/len(actual_words)\n",
    "print()\n",
    "print()\n",
    "print(f\"Accuracy = {accuracy*100}% on testing data\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
